import requests
import json
import os
import re
import time
import akshare as ak
from datetime import datetime
from utils import logger, retry

class NewsAnalyst:
    def __init__(self):
        self.api_key = os.getenv("LLM_API_KEY")
        self.base_url = os.getenv("LLM_BASE_URL")
        self.model = os.getenv("LLM_MODEL", "gpt-3.5-turbo")
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

    @retry(retries=2, delay=2)
    def fetch_news_titles(self, keyword):
        """
        [ä¿®å¤] æ¢å¤è¡Œä¸šæ–°é—»æŠ“å–èƒ½åŠ› (æ”¹ç”¨ä¸œè´¢æº)
        """
        if not keyword: return []
        
        news_list = []
        try:
            # å°è¯•1: ä¸œæ–¹è´¢å¯Œä¸ªè‚¡/æ¿å—æ–°é—»
            # æœç´¢ç­–ç•¥ï¼šç›´æ¥æœå…³é”®è¯å¯èƒ½æ²¡æœ‰APIï¼Œæˆ‘ä»¬ä½¿ç”¨"è¦é—»"æ¥å£ç„¶åæœ¬åœ°è¿‡æ»¤
            df = ak.stock_news_em(symbol="è¦é—»")
            
            keys = keyword.split()
            
            for _, row in df.iterrows():
                title = str(row.get('title', ''))
                # ä¸œè´¢åªæœ‰title, content, public_time
                if any(k in title for k in keys):
                    news_list.append(f"[{row.get('public_time','')[-5:]}] {title}")
            
            # å¦‚æœæ²¡æŠ“åˆ°ï¼Œå°è¯•å¤‡ç”¨æºï¼šå…¨çƒå¿«è®¯
            if not news_list:
                df_global = ak.stock_info_global_ems()
                for _, row in df_global.iterrows():
                    content = str(row.get('content', ''))
                    if any(k in content for k in keys):
                        news_list.append(f"[å¿«è®¯] {content[:60]}...")

            if not news_list:
                return [f"è¿‘æœŸæ— '{keyword}'ç›´æ¥ç›¸å…³èµ„è®¯ï¼Œå»ºè®®å…³æ³¨ç›˜é¢èµ„é‡‘æµå‘ã€‚"]
                
            return news_list[:5] 
            
        except Exception as e:
            logger.warning(f"è¡Œä¸šæ–°é—»æŠ“å–å¤±è´¥ {keyword}: {e}")
            return ["æ•°æ®æºæš‚æ—¶ä¸å¯ç”¨"]

    def _clean_json(self, text):
        try:
            match = re.search(r'```json\s*(\{.*?\})\s*```', text, re.DOTALL)
            if match: return match.group(1)
            match = re.search(r'\{.*\}', text, re.DOTALL)
            if match: return match.group(0)
            return text
        except: return text

    @retry(retries=2, delay=2)
    def analyze_fund_v4(self, fund_name, tech_indicators, macro_summary, sector_news):
        # ... (æŠ•å§”ä¼š Prompt é€»è¾‘ä¿æŒä¸å˜ï¼Œä¸ºèŠ‚çœç¯‡å¹…çœç•¥ï¼Œè¯·å¤ç”¨ V14.1 çš„é€»è¾‘) ...
        # è¯·åŠ¡å¿…ä¿ç•™ä¹‹å‰å¸¦æœ‰ "æŠ•å§”ä¼šæœ€é«˜å®ªç« " çš„ Prompt ä»£ç 
        
        score = tech_indicators.get('quant_score', 50)
        trend = tech_indicators.get('trend_weekly', 'æ— è¶‹åŠ¿')
        valuation = tech_indicators.get('valuation_desc', 'æœªçŸ¥')
        obv_slope = tech_indicators.get('flow', {}).get('obv_slope', 0)
        
        if obv_slope > 1.5: money_flow = "ä¸»åŠ›å¤§å¹…æŠ¢ç­¹"
        elif obv_slope > 0: money_flow = "æ¸©å’Œæµå…¥"
        elif obv_slope < -1.5: money_flow = "ä¸»åŠ›åšå†³å‡ºè´§"
        else: money_flow = "èµ„é‡‘æµå‡º"
        
        vol_ratio = tech_indicators.get('risk_factors', {}).get('vol_ratio', 1.0)
        if vol_ratio < 0.6: volume_status = "æåº¦ç¼©é‡(æ²¡äººç©)"
        elif vol_ratio < 0.8: volume_status = "ç¼©é‡"
        elif vol_ratio > 2.0: volume_status = "æ”¾é‡æ»æ¶¨" if score < 40 else "æ”¾é‡ä¸Šæ”»"
        else: volume_status = "é‡èƒ½æ­£å¸¸"

        prompt = f"""
        ä½ ç°åœ¨æ˜¯ã€ç„é“åŸºé‡‘æŠ•å§”ä¼šã€‘çš„ä¼šè®®è®°å½•å‘˜ã€‚å¯¹æ ‡çš„ã€{fund_name}ã€‘è¿›è¡ŒæŠ•èµ„å†³ç­–ã€‚

        ### ğŸ“œ æŠ•å§”ä¼šæœ€é«˜å®ªç« 
        1. **é‡å‰‘æ— é”‹**ï¼šåªåƒå‘¨æœŸå’Œè¶‹åŠ¿çš„é’±ã€‚
        2. **æ•°æ®ä¸ºç‹**ï¼šç¡¬æ•°æ®(ä¼°å€¼/èµ„é‡‘) æƒé‡ > æ–°é—»æƒ…ç»ªã€‚
        3. **åŒæ¶é£é™©**ï¼šç”Ÿå­˜ç¬¬ä¸€ï¼Œå®å¯è¸ç©ºä¸å¯å¥—ç‰¢ã€‚

        ### ğŸ“Š æ ‡çš„ç¡¬æ•°æ®
        - æˆ˜æœ¯è¯„åˆ†: {score}åˆ†
        - å‘¨æœŸä¼°å€¼: {valuation}
        - èµ„é‡‘æµå‘: {money_flow}
        - é‡èƒ½çŠ¶æ€: {volume_status}
        - å‘¨çº¿è¶‹åŠ¿: {trend}

        ### ğŸŒ æƒ…æŠ¥
        - å®è§‚: {macro_summary[:200]}
        - è¡Œä¸š: {str(sector_news)[:500]}

        ### ğŸ—£ï¸ æ¨¡æ‹Ÿå§”å‘˜å‘è¨€

        **1. ğŸ¦Š CGO (å¤šå¤´):** è´ªå©ªï¼Œæ‰¾åˆ©å¥½ï¼Œå¼ºè°ƒèµ„é‡‘æµå…¥æˆ–ä½ä¼°ã€‚
        **2. ğŸ» CRO (ç©ºå¤´):** ææƒ§ï¼Œæ‰¾èƒŒç¦»ï¼Œå¼ºè°ƒç¼©é‡æˆ–åˆ©å¥½å‡ºå°½ã€‚
        **3. âš–ï¸ ä¸»å¸­ (è£å†³):** å¬å–è¾©è®ºï¼Œç»“åˆç¡¬æ•°æ®æƒé‡ï¼Œç»™å‡ºæœ€ç»ˆä¿®æ­£åˆ†(-30~+30)å’Œå®šè°ƒã€‚

        å¿…é¡»è¿”å› JSON:
        {{
            "bull_view": "CGOè§‚ç‚¹(30å­—)",
            "bear_view": "CROè§‚ç‚¹(30å­—)",
            "chairman_conclusion": "ä¸»å¸­è£å†³(50å­—)",
            "adjustment": æ•´æ•°,
            "risk_alert": "æ— "æˆ–"é£é™©å†…å®¹"
        }}
        """

        payload = {
            "model": self.model,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.3,
            "max_tokens": 1000
        }
        
        try:
            response = requests.post(f"{self.base_url}/chat/completions", headers=self.headers, json=payload, timeout=45)
            if response.status_code != 200: return self._fallback_result()
            data = json.loads(self._clean_json(response.json()['choices'][0]['message']['content']))
            return {
                "bull_say": data.get("bull_view", "è§‚ç‚¹æ¨¡ç³Š"),
                "bear_say": data.get("bear_view", "é£é™©ä¸æ˜"),
                "comment": data.get("chairman_conclusion", "éœ€äººå·¥å¤æ ¸"),
                "adjustment": int(data.get("adjustment", 0)),
                "risk_alert": data.get("risk_alert", "æ— ")
            }
        except Exception as e:
            logger.error(f"æŠ•å§”ä¼šå´©æºƒ {fund_name}: {e}")
            return self._fallback_result()

    def _fallback_result(self):
        return {"bull_say": "æ•°æ®ä¸è¶³", "bear_say": "é£é™©æœªçŸ¥", "comment": "APIå¼‚å¸¸ï¼Œç»´æŒåŸåˆ¤", "adjustment": 0, "risk_alert": "API Error"}

    def review_report(self, text): return "å·²å½’æ¡£"
    def advisor_review(self, text, macro): return "å·²å®¡é˜…"
