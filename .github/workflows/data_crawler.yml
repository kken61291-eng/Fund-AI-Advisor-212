name: Data Crawler (Batch Updater)

on:
  schedule:
    # [æ ¸å¿ƒä¿®æ”¹] æ¯å°æ—¶æ‰§è¡Œä¸€æ¬¡ (0åˆ†æ—¶åˆ»)ï¼Œè¦†ç›–å…¨çƒå¸‚åœº(ç¾è‚¡/æ¸¯è‚¡/æœŸè´§)äº¤æ˜“æ—¶æ®µ
    - cron: '0 * * * *'
  workflow_dispatch:

concurrency: 
  group: data-crawler
  cancel-in-progress: false

jobs:
  update_data:
    runs-on: ubuntu-latest
    env:
      TZ: Asia/Shanghai

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        cache: 'pip'

    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt

    - name: ğŸ•·ï¸ Run Market Data Crawler
      env:
        # å¦‚æœçˆ¬è™«éœ€è¦ Tushareï¼Œè¯·ä¿ç•™è¿™ä¸ª
        TUSHARE_TOKEN: ${{ secrets.TUSHARE_TOKEN }}
      run: |
        python batch_updater.py

    - name: ğŸ“¡ Run News Crawler
      run: |
        python news_loader.py

    - name: Commit and Push Data
      run: |
        git config --global user.name "GitHub Action"
        git config --global user.email "action@github.com"
        
        # æ£€æŸ¥ data_cache (è¡Œæƒ…) å’Œ data_news (æ–°é—») æ˜¯å¦æœ‰å˜åŒ–
        if [[ -n $(git status --porcelain data_cache/ data_news/) ]]; then
          git add data_cache/*.csv
          git add data_news/*.jsonl
          git commit -m "ğŸ’¾ Auto-save market & news data [skip ci]"
          git pull --rebase origin main
          git push
        else
          echo "No new data fetched."
        fi
