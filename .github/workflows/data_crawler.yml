name: Data Crawler (Batch Updater)

on:
  schedule:
    # UTCæ—¶é—´ 1:30 - 7:30ï¼Œå¯¹åº”åŒ—äº¬æ—¶é—´ 09:30 - 15:30
    # æ¯å°æ—¶çš„ç¬¬30åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡ï¼Œè´Ÿè´£æ¬è¿æ•°æ®
    - cron: '30 0-7 * * 1-5'
  workflow_dispatch: # å…è®¸æ‰‹åŠ¨ç‚¹å‡»æŒ‰é’®è§¦å‘

concurrency: 
  group: data-crawler
  cancel-in-progress: false

jobs:
  update_data:
    runs-on: ubuntu-latest
    env:
      TZ: Asia/Shanghai

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        cache: 'pip'

    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt

    # --- ä»»åŠ¡ 1: æŠ“å–è¡Œæƒ…æ•°æ® (è€—æ—¶è¾ƒé•¿ï¼Œæœ‰ä¼‘çœ ) ---
    - name: ğŸ•·ï¸ Run Market Data Crawler
      env:
        TUSHARE_TOKEN: ${{ secrets.TUSHARE_TOKEN }}
      run: |
        python batch_updater.py

    # --- ä»»åŠ¡ 2: æŠ“å–æ–°é—»æ•°æ® (é€Ÿåº¦è¾ƒå¿«) ---
    - name: ğŸ“¡ Run News Crawler
      run: |
        python news_loader.py

    # --- æäº¤æ‰€æœ‰æ•°æ® ---
    - name: Commit and Push Data Cache
      run: |
        git config --global user.name "GitHub Action"
        git config --global user.email "action@github.com"
        
        # æ£€æŸ¥ data_cache (è¡Œæƒ…) æˆ– data_news (æ–°é—») æ˜¯å¦æœ‰å˜åŒ–
        if [[ -n $(git status --porcelain data_cache/ data_news/) ]]; then
          
          # [å…³é”®] åŒæ—¶æ·»åŠ ä¸¤ä¸ªç›®å½•
          git add data_cache/*.csv
          git add data_news/*.jsonl
          
          git commit -m "ğŸ’¾ Auto-save market & news data [skip ci]"
          
          # æ‹‰å–æœ€æ–°ä»£ç é˜²æ­¢å†²çª (Rebase æ¨¡å¼)
          git pull --rebase origin main
          git push
        else
          echo "No new data fetched."
        fi
