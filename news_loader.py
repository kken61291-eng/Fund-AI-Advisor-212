import akshare as ak
import json
import os
import time
import pandas as pd
from datetime import datetime
import hashlib
import pytz # [å…³é”®] å¼•å…¥æ—¶åŒºåº“

# --- é…ç½® ---
DATA_DIR = "data_news"
if not os.path.exists(DATA_DIR):
    os.makedirs(DATA_DIR)

def get_beijing_time():
    """[å…³é”®ä¿®å¤] è·å–åŒ—äº¬æ—¶é—´ï¼Œç¡®ä¿ä¸ news_analyst è¯»å–é€»è¾‘ä¸€è‡´"""
    return datetime.now(pytz.timezone('Asia/Shanghai'))

def get_today_str():
    """ä½¿ç”¨åŒ—äº¬æ—¶é—´ç”Ÿæˆæ—¥æœŸå­—ç¬¦ä¸²"""
    return get_beijing_time().strftime("%Y-%m-%d")

def generate_news_id(item):
    """ç”Ÿæˆæ–°é—»å”¯ä¸€æŒ‡çº¹ï¼Œé˜²æ­¢é‡å¤"""
    # ç»„åˆ æ—¶é—´+æ ‡é¢˜ ä½œä¸ºå”¯ä¸€æ ‡è¯†
    raw = f"{item.get('time','')}{item.get('title','')}"
    return hashlib.md5(raw.encode('utf-8')).hexdigest()

def clean_time_str(t_str):
    """æ ‡å‡†åŒ–æ—¶é—´æ ¼å¼ä¸º YYYY-MM-DD HH:MM:SS"""
    if not t_str: return ""
    try:
        # å°è¯•è§£æå¸¸è§æ ¼å¼
        if len(str(t_str)) == 10: # å¯èƒ½æ˜¯æ—¶é—´æˆ³ 1700000000
             return datetime.fromtimestamp(int(t_str)).strftime("%Y-%m-%d %H:%M:%S")
        if len(str(t_str)) > 19:
            return str(t_str)[:19]
        return str(t_str)
    except:
        return str(t_str)

def fetch_and_save_news():
    today_date = get_today_str()
    print(f"ğŸ“¡ [NewsLoader] å¯åŠ¨åŒæºæŠ“å– (EastMoney + CLS) - {today_date} (Beijing Time)...")
    
    all_news_items = []

    # ----------------------------------------------------
    # 1. æŠ“å– ä¸œæ–¹è´¢å¯Œ (EastMoney) 7x24
    # ----------------------------------------------------
    try:
        print("   - æ­£åœ¨æŠ“å–: ä¸œæ–¹è´¢å¯Œ (EastMoney)...")
        df_em = ak.stock_telegraph_em()
        if df_em is not None and not df_em.empty:
            for _, row in df_em.iterrows():
                title = str(row.get('title', '')).strip()
                content = str(row.get('content', '')).strip()
                public_time = clean_time_str(row.get('public_time', ''))
                
                if not title or len(title) < 2: continue
                
                all_news_items.append({
                    "time": public_time,
                    "title": title,
                    "content": content,
                    "source": "EastMoney"
                })
    except Exception as e:
        print(f"   âŒ ä¸œè´¢æŠ“å–å¤±è´¥: {e}")

    # ----------------------------------------------------
    # 2. æŠ“å– è´¢è”ç¤¾ (CLS) ç”µæŠ¥
    # ----------------------------------------------------
    try:
        print("   - æ­£åœ¨æŠ“å–: è´¢è”ç¤¾ (CLS)...")
        # è´¢è”ç¤¾æ¥å£è¿”å›å­—æ®µé€šå¸¸ä¸º: title, content, ctime
        df_cls = ak.stock_telegraph_cls()
        if df_cls is not None and not df_cls.empty:
            for _, row in df_cls.iterrows():
                title = str(row.get('title', '')).strip()
                content = str(row.get('content', '')).strip()
                # è´¢è”ç¤¾çš„æ—¶é—´å­—æ®µå¯èƒ½å« ctime æˆ– publish_time
                raw_time = row.get('ctime', row.get('publish_time', ''))
                public_time = clean_time_str(raw_time)
                
                # è´¢è”ç¤¾æœ‰äº›åªæœ‰contentæ²¡æœ‰titleï¼Œæˆ–è€…titleå°±æ˜¯content
                if not title and content:
                    title = content[:30] + "..."
                
                if not title: continue

                all_news_items.append({
                    "time": public_time,
                    "title": title,
                    "content": content,
                    "source": "CLS"
                })
    except Exception as e:
        print(f"   âŒ è´¢è”ç¤¾æŠ“å–å¤±è´¥: {e}")

    # ----------------------------------------------------
    # 3. åˆå¹¶å…¥åº“ & å»é‡
    # ----------------------------------------------------
    if not all_news_items:
        print("âš ï¸ æœªè·å–åˆ°ä»»ä½•æ–°é—»æ•°æ®")
        return

    # [å…³é”®] ç¡®ä¿æ–‡ä»¶åä½¿ç”¨çš„æ˜¯åŒ—äº¬æ—¶é—´
    today_file = os.path.join(DATA_DIR, f"news_{today_date}.jsonl")
    
    # è¯»å–å·²å­˜ ID
    existing_ids = set()
    if os.path.exists(today_file):
        with open(today_file, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    saved_item = json.loads(line)
                    if 'id' in saved_item:
                        existing_ids.add(saved_item['id'])
                except: pass

    # å†™å…¥æ–°æ•°æ®
    new_count = 0
    # æŒ‰æ—¶é—´å€’åºæ’åˆ—ï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    all_news_items.sort(key=lambda x: x['time'], reverse=True)

    with open(today_file, 'a', encoding='utf-8') as f:
        for item in all_news_items:
            item_id = generate_news_id(item)
            item['id'] = item_id
            
            if item_id not in existing_ids:
                f.write(json.dumps(item, ensure_ascii=False) + "\n")
                existing_ids.add(item_id)
                new_count += 1
    
    print(f"âœ… å…¥åº“å®Œæˆ: æ–°å¢ {new_count} æ¡ | æ€»å­˜é‡ {len(existing_ids)} æ¡ | ç›®æ ‡æ–‡ä»¶: {today_file}")

if __name__ == "__main__":
    fetch_and_save_news()
