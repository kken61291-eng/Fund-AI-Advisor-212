import akshare as ak
import pandas as pd
import os
import json
import time
import random
from datetime import datetime
from utils import logger, get_beijing_time

class NewsLoader:
    def __init__(self):
        self.CACHE_DIR = "data_news"
        if not os.path.exists(self.CACHE_DIR):
            os.makedirs(self.CACHE_DIR)
        
        # å®šä¹‰æ–°é—»æ–‡ä»¶ï¼ŒæŒ‰æ—¥æœŸå­˜å‚¨ï¼Œå¦‚ news_2026-02-09.jsonl
        self.today_str = get_beijing_time().strftime("%Y-%m-%d")
        self.file_path = os.path.join(self.CACHE_DIR, f"news_{self.today_str}.jsonl")

    def _load_existing_titles(self):
        """è¯»å–å·²å­˜æ–°é—»çš„æ ‡é¢˜ï¼Œç”¨äºå»é‡"""
        titles = set()
        if os.path.exists(self.file_path):
            with open(self.file_path, 'r', encoding='utf-8') as f:
                for line in f:
                    try:
                        data = json.loads(line)
                        titles.add(data.get('title', '').strip())
                    except: pass
        return titles

    def fetch_and_save(self):
        """
        è·å–æ–°é—»å¹¶è¿½åŠ ä¿å­˜
        """
        existing_titles = self._load_existing_titles()
        new_items = []
        
        logger.info(f"ğŸ“¡ [NewsLoader] å¼€å§‹å¢é‡æŠ“å–æ–°é—»...")
        
        # --- æº1: ä¸œè´¢è´¢ç»å¯¼è¯» ---
        try:
            df = ak.stock_news_em(symbol="è¦é—»")
            for _, row in df.iterrows():
                title = str(row.get('æ–°é—»æ ‡é¢˜') or row.get('title')).strip()
                pub_time = str(row.get('å‘å¸ƒæ—¶é—´') or row.get('public_time'))
                content = str(row.get('æ–°é—»å†…å®¹') or row.get('content') or title)
                
                # ç®€å•å»é‡å’Œè¿‡æ»¤
                if title not in existing_titles and len(title) > 5:
                    new_items.append({
                        "source": "EastMoney",
                        "time": pub_time,
                        "title": title,
                        "content": content[:500] # åªå­˜æ‘˜è¦ï¼ŒèŠ‚çœç©ºé—´
                    })
                    existing_titles.add(title)
            time.sleep(2)
        except Exception as e:
            logger.warning(f"ä¸œè´¢æ–°é—»æŠ“å–å—é˜»: {e}")

        # --- æº2: è´¢è”ç¤¾ç”µæŠ¥ (æ¨¡æ‹Ÿ) ---
        # è¿™é‡Œå¯ä»¥ä½¿ç”¨æ‚¨çš„ requests ä»£ç é€»è¾‘ï¼Œæ­¤å¤„ç®€åŒ–æ¼”ç¤º
        # ...

        # --- ä¿å­˜å…¥åº“ ---
        if new_items:
            # æŒ‰æ—¶é—´æ’åºï¼ˆå¯é€‰ï¼Œå°½é‡ä¿æŒæœ‰åºï¼‰
            new_items.sort(key=lambda x: x['time'])
            
            with open(self.file_path, 'a', encoding='utf-8') as f:
                for item in new_items:
                    f.write(json.dumps(item, ensure_ascii=False) + "\n")
            
            logger.info(f"ğŸ’¾ [NewsLoader] æ–°å¢å…¥åº“ {len(new_items)} æ¡æ–°é—»ã€‚")
        else:
            logger.info("ğŸ’¤ [NewsLoader] æš‚æ— æ–°æ¶ˆæ¯ã€‚")

if __name__ == "__main__":
    loader = NewsLoader()
    loader.fetch_and_save()
